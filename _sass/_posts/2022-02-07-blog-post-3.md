---
layout: post
title: Blog Post 3
---



2022-02-07

# Web Scraping

## 1.	First part

My favorite movie series is Harry Potter, the story of the wizarding world. In this blog I am going to scrape the data containing the information of the actors and display the results. Here is the start URL.

## 2.	Second part

There are three major functions in total. 

(a)	First, we write a function to scrape the data from the URL. 

```python
def parse(self,response):
  '''
  The function has two variables: self and response.
  This function allows us to read the data from one page to the other. 
  '''
      url= response.url + "fullcredits/"
      #url = "https://www.imdb.com/title/tt0106145/fullcredits/?ref_=tt_cl_sm/"
      yield Request(url,callback = self.parse_full_credits)
```

(b)	Then, we write a function called parse_full_credits () to scrape all the actor names and go to their pages.

```python
def parse_full_credits(self,response):
  '''
  The function has two variables: self and response. 
  The function works to scrape all the actor names and go to their own pages.
  '''
        links = response.css("td.primary_photo").css("a")
        actorname = [link.attrib["href"] for link in links]
        for i in actorname:
            url ="https://www.imdb.com/"+ i
            yield Request(url,callback = self.parse_actor_page)
```

(c)	After that we write a function parse_actor_page (), which scrapes the name of the actor and the movies he or she has worked on.

```python
def parse_actor_page(self,response):
  '''
  The function has two variables: self and response. 
  The function works to scrape the name of the actor and the movies he or she has worked on.

  '''
    actor = response.css("span.itemprop::text").get()
    boxes = response.css("div#content-2-wide.redesign")
    Movie = boxes.css("div.filmo-row").css("b").css("a::text").getall()
    Movie = "#".join(Movie)
                
    for m in Movie.split("#"):
        yield{
            "actor":actor,
            "Movie_or_TV_name":m
             }

def parse_start_url(self,response):
    return self.parse(response)
```

## 3.	Third part

Now we put all the functions together and here it is:

```python
import scrapy
import random
from scrapy.spiders import Spider
from scrapy.http import Request
from scrapy.linkextractors import LinkExtractor


class ImdbSpider(scrapy.Spider):
   
    name = "imdb_spider"
       
    start_urls = [
        "https://www.imdb.com/title/tt0106145/"
    ]


    def parse(self,response):
        url= response.url + "fullcredits/"
        #url = "https://www.imdb.com/title/tt0106145/fullcredits/?ref_=tt_cl_sm/"
        yield Request(url,callback = self.parse_full_credits)
      
    def parse_full_credits(self,response):
        links = response.css("td.primary_photo").css("a")
        actorname = [link.attrib["href"] for link in links]
        for i in actorname:
            url ="https://www.imdb.com/"+ i
            yield Request(url,callback = self.parse_actor_page)
    

    def parse_actor_page(self,response):
        actor = response.css("span.itemprop::text").get()
        boxes = response.css("div#content-2-wide.redesign")
        Movie = boxes.css("div.filmo-row").css("b").css("a::text").getall()
        Movie = "#".join(Movie)
                
        for m in Movie.split("#"):
            yield{
                "actor":actor,
                "Movie_or_TV_name":m
            }

    def parse_start_url(self,response):
        return self.parse(response)
```

## 4.	Fourth part
Then we create a table of the characters mentioned the most frequent:

```python
import pandas as pd

df = pd.read_csv("result.csv")

df1 = df.groupby("Movie_or_TV_name").count() 

df2 = df1.sort_values(by="actor" , ascending=False) 
print(df2[0:20])

df5=df[df["Movie_or_TV_name"]=="Hunter"]
print(df5)
print(df5.count())
#print(df4)

```

Thank you!!!